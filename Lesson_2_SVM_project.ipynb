{
 "metadata": {
  "name": "",
  "signature": "sha256:463738bd68b0657173786d1d98dd11298837612a0c4bf63ae50b7aec10b38d59"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "import pickle\n",
      "import numpy\n",
      "\n",
      "from sklearn import cross_validation\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_selection import SelectPercentile, f_classif\n",
      "\n",
      "\n",
      "\n",
      "def preprocess(words_file = \"/Users/olehdubno/Desktop/ud120-projects-master/tools/word_data.pkl\", authors_file=\"/Users/olehdubno/Desktop/ud120-projects-master/tools/email_authors.pkl\"):\n",
      "    \"\"\" \n",
      "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
      "        and the corresponding authors (by default email_authors.pkl) and performs\n",
      "        a number of preprocessing steps:\n",
      "            -- splits into training/testing sets (10% testing)\n",
      "            -- vectorizes into tfidf matrix\n",
      "            -- selects/keeps most helpful features\n",
      "\n",
      "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
      "\n",
      "        4 objects are returned:\n",
      "            -- training/testing features\n",
      "            -- training/testing labels\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    ### the words (features) and authors (labels), already largely preprocessed\n",
      "    ### this preprocessing will be repeated in the text learning mini-project\n",
      "    word_data = pickle.load( open(words_file, \"r\"))\n",
      "    authors = pickle.load( open(authors_file, \"r\") )\n",
      "\n",
      "    ### test_size is the percentage of events assigned to the test set (remainder go into training)\n",
      "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
      "\n",
      "\n",
      "\n",
      "    ### text vectorization--go from strings to lists of numbers\n",
      "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
      "                                 stop_words='english')\n",
      "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
      "    features_test_transformed  = vectorizer.transform(features_test)\n",
      "\n",
      "\n",
      "\n",
      "    ### feature selection, because text is super high dimensional and \n",
      "    ### can be really computationally chewy as a result\n",
      "    selector = SelectPercentile(f_classif, percentile=10)\n",
      "    selector.fit(features_train_transformed, labels_train)\n",
      "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
      "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
      "\n",
      "    ### info on the data\n",
      "    print \"no. of Chris training emails:\", sum(labels_train)\n",
      "    print \"no. of Sara training emails:\", len(labels_train)-sum(labels_train)\n",
      "\n",
      "\n",
      "    return features_train_transformed, features_test_transformed, labels_train, labels_test\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "\"\"\" \n",
      "    this is the code to accompany the Lesson 2 (SVM) mini-project\n",
      "\n",
      "    use an SVM to identify emails from the Enron corpus by their authors\n",
      "    \n",
      "    Sara has label 0\n",
      "    Chris has label 1\n",
      "\n",
      "\"\"\"\n",
      "    \n",
      "import sys\n",
      "from time import time\n",
      "\n",
      "\n",
      "### features_train and features_test are the features for the training\n",
      "### and testing datasets, respectively\n",
      "### labels_train and labels_test are the corresponding item labels\n",
      "features_train, features_test, labels_train, labels_test = preprocess()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no. of Chris training emails: 7936\n",
        "no. of Sara training emails: 7884\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/olehdubno/anaconda/lib/python2.7/site-packages/numpy/lib/utils.py:95: DeprecationWarning: `fprob` is deprecated!\n",
        "fprob is deprecated in scipy 0.14, use stats.f.sf or special.fdtrc instead\n",
        "\n",
        "  warnings.warn(depdoc, DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#SVM - Running the linear Kernel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SVC(kernel='linear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(features_train,labels_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = clf.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "t0 = time()\n",
      "clf.fit(features_train,labels_train)\n",
      "print 'training time',round(time()-t0,3) ,'s'\n",
      "t0 = time()\n",
      "print clf.score(features_test,labels_test)\n",
      "print 'predicting time', round(time()-t0,3),'s'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training time 164.848 s\n",
        "0.984072810011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "predicting time 17.303 s\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "acc = accuracy_score(pred, labels_test)\n",
      "\n",
      "print acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.984072810011\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Increasing the speed of the SVM classifier by dividing by 100 (still using the linear kernel)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train = features_train[:len(features_train)/100] \n",
      "labels_train = labels_train[:len(labels_train)/100] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "clf = SVC(kernel='linear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t0 = time()\n",
      "clf.fit(features_train,labels_train)\n",
      "print 'training time',round(time()-t0,3) ,'s'\n",
      "t0 = time()\n",
      "print clf.score(features_test,labels_test)\n",
      "print 'predicting time', round(time()-t0,3),'s'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training time 0.105 s\n",
        "0.884527872582"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "predicting time 1.037 s\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = clf.predict(features_test)\n",
      "\n",
      "from sklearn.metrics import accuracy_score\n",
      "acc = accuracy_score(pred, labels_test)\n",
      "\n",
      "print acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.884527872582\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A 10% change!!!!! huge difference, although probably way way faster."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If speed is a major consideration (and for many real-time machine learning applications, it certainly is) then you may want to sacrifice a bit of accuracy if it means you can train/predict faster."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Using the rbf kernel\n",
      "#### this one highlights and envelops all the data points"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train = features_train[:len(features_train)/100] \n",
      "labels_train = labels_train[:len(labels_train)/100] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import SVC\n",
      "clf = SVC(C=10000.0,kernel='rbf') #optimizing the C value increases the score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t0 = time()\n",
      "clf.fit(features_train,labels_train)\n",
      "print 'training time',round(time()-t0,3) ,'s'\n",
      "t0 = time()\n",
      "print clf.score(features_test,labels_test)\n",
      "print 'predicting time', round(time()-t0,3),'s'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training time 0.112 s\n",
        "0.892491467577"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "predicting time 0.939 s\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = clf.predict(features_test)\n",
      "\n",
      "from sklearn.metrics import accuracy_score\n",
      "acc = accuracy_score(pred, labels_test)\n",
      "\n",
      "print acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.892491467577\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### wow this score sucks by a lot. the linear method is a lot better (given C=1.0)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, Once you've optimized the C value for your RBF kernel, the accuracy goes up. The higher the C value the better the score."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Running rbf kernel on the full set with an optimized C"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SVC(C=10000.0,kernel='rbf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t0 = time()\n",
      "clf.fit(features_train,labels_train)\n",
      "print 'training time',round(time()-t0,3) ,'s'\n",
      "t0 = time()\n",
      "print clf.score(features_test,labels_test)\n",
      "print 'predicting time', round(time()-t0,3),'s'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training time 107.977 s\n",
        "0.990898748578"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "predicting time 10.975 s\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Just wow!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = clf.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pred[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pred[26]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pred[50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "1758"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chris_total = 0 \n",
      "for i in pred:\n",
      "    if i == 1:\n",
      "        chris_total += i\n",
      "print \"emails classified to be chris'\", chris_total"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "emails classified to be chris' 877\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = []\n",
      "[n.append(e) for e in pred if e == 1]\n",
      "len(n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "877"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Naive Bayes is great for text--it\u2019s faster and generally gives better performance than an SVM for this particular problem. Of course, there are plenty of other problems where an SVM might work better. Knowing which one to try when you\u2019re tackling a problem for the first time is part of the art and science of machine learning."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}